# How Large Language Models Deal With Misspellings

**Author**: Ida Caspary (Imperial College London)  
**Part of**: *"Slip Happens: How Large Language Models Deal With Misspellings"*  
**Colab Notebook**: [Link](https://colab.research.google.com/drive/1AzfSVcl8XVs6IPQD5RVKr43oYUZ9p3qN?usp=sharing)  
**GitHub**: [https://github.com/IdaCy/mech-typo-detect](https://github.com/IdaCy/mech-typo-detect)

This repository contains code and data for analyzing how a 7B-parameter Mistral model handles typographical errors. The accompanying paper explores the internal hidden states, focusing on how a single dimension or small subspace can encode “typo anomalies” and facilitate LLM resilience. In particular, neuron **#2070** in layer **2** stands out as highly sensitive to spelling distortions.

---

## Project Structure

- **analyses_results**  
  Stores outputs from PCA, neuron-dissection, and hooking experiments (e.g., `.pt` files with difference vectors, CSV logs of ablation runs, and final results or plots).
  
- **containers**  
  Holds any containerization or environment-setup files, if used.

- **extractions**  
  Contains `.pt` dumps of hidden states, attention scores, and logits for each input prompt pair (clean vs. typo). Generated by the inference scripts.

- **logs**  
  Contains `.log` files capturing verbose runtime information from hooking or ablation scripts.

- **scripts**  
  - **mistral/** includes the primary inference scripts.  
  - **analyses/** focuses on extracting and comparing hidden-state differences, running PCA, and computing explained variances.  
  - **investigations/** contains deeper neuron-level or subspace-level explorations, such as hooking and correlation tests.

The paper itself  explains all relevant experiments in detail— from building a 5000-pair dataset of clean vs. typo prompts, to using PCA on the difference-of-activations, to hooking neurons or entire dimensions in the model.

---

## Usage

1. **Colab Notebook**  
   The quickest way to reproduce key results is via [the Google Colab link](https://colab.research.google.com/drive/1AzfSVcl8XVs6IPQD5RVKr43oYUZ9p3qN?usp=sharing). It walks through loading the data, running PCA, analyzing neuron #2070, and performing hooking experiments.

2. **Local or HPC Environment**  
   - Clone this repo:  
     ```
     git clone https://github.com/IdaCy/mech-typo-detect.git
     cd mech-typo-detect
     ```  
   - Ensure Python 3.9+ or similar, plus PyTorch, Transformers, NumPy, Matplotlib, scikit-learn, etc.
   - Place your `cleanQs.csv` and `typoQs.csv` prompts in `prompts/preprocessed/` (or adjust paths in the scripts).
   - Run inference (to generate `.pt` activation files) from `scripts/mistral/`.  
   - Proceed with difference computation, PCA, or hooking by calling scripts in `scripts/analyses/` and `scripts/investigations/`.

3. **Outputs & Logs**  
   - Intermediate `.pt` files end up in `extractions/` or `analyses_results/`.  
   - PCA results, hooking outcomes, and correlation data are stored in `analyses_results/` subdirectories.  
   - Console messages also appear in `.log` files within `logs/`.

---

## Contact & License

Just open an issue or pull request on GitHub if you find any problems or have ideas to extend the project!
